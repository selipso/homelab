services:
  litellm:
    networks:
      - monitoring
      - proxy
    image: ghcr.io/berriai/litellm:main-stable
    #########################################
    ## Uncomment these lines to start proxy with a config.yaml file ##
    # volumes:
    #  - ./config.yaml:/app/config.yaml <<- this is missing in the docker-compose file currently
    # command:
    #  - "--config=/app/config.yaml"
    ##############################################
    ports:
      - "4400:4000" # Map the container port to the host, change the host port if necessary
    environment:
      DATABASE_URL: "postgresql://llmproxy:{{ POSTGRES_PASSWORD }}@llmdb:5432/litellm"
      STORE_MODEL_IN_DB: "True" # allows adding models to proxy via UI
      LITELLM_MASTER_KEY: "{{ LITELLM_MASTER_KEY }}"
    deploy:
      replicas: 1
    depends_on:
      - llmdb
    healthcheck: # Defines the health check configuration for the container
      test: [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 http://localhost:4000/health/liveliness || exit 1",
        ] # Command to execute for health check
      interval: 30s # Perform health check every 30 seconds
      timeout: 10s # Health check command times out after 10 seconds
      retries: 3 # Retry up to 3 times if health check fails
      start_period: 40s # Wait 40 seconds after container start before beginning health checks

  n8n:
    image: docker.n8n.io/n8nio/n8n
    ports:
      - "5678:5678"
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=llmdb
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=litellm
      - DB_POSTGRESDB_USER=llmproxy
      - DB_POSTGRESDB_PASSWORD={{ POSTGRES_PASSWORD }}
      - N8N_SECURE_COOKIE=false
    volumes:
      - /mnt/apps/shared/n8n:/home/node/.n8n
    depends_on:
      - llmdb
    networks:
      - monitoring
    deploy:
      replicas: 1

  llmdb:
    networks:
      - monitoring
    image: postgres:16
    environment:
      POSTGRES_DB: litellm
      POSTGRES_USER: llmproxy
      POSTGRES_PASSWORD: {{ POSTGRES_PASSWORD }}
    deploy:
      replicas: 1
    volumes:
      - /mnt/apps/shared/monitoring/data:/var/lib/postgresql/data # Persists Postgres data across container restarts
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d litellm -U llmproxy"]
      interval: 1s
      timeout: 5s
      retries: 10

  prometheus:
    networks:
      - monitoring
    image: prom/prometheus:v3.4.1
    volumes:
      - /mnt/apps/shared/prometheus:/prometheus
      - /mnt/apps/shared/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=10y"
      - "--storage.tsdb.retention.size=150GB"
    deploy:
      replicas: 1

  grafana:
    networks:
      - monitoring
    image: grafana/grafana:12.0.2
    ports:
      - "4500:3000"
    volumes:
      - /mnt/apps/shared/grafana:/var/lib/grafana # Persists Grafana data across container restarts
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD={{ DASHBOARD_PASSWORD }}
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD-SHELL", "curl -f localhost:3000/api/health && echo 'ready'"]
      interval: 10s
      retries: 30
    deploy:
      replicas: 1

networks:
  monitoring:
    external: true
  proxy:
    external: true
