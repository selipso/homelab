networks:
  supabase-net:
    external: true
volumes:
  db-config:
services:
  analytics:
    hostname: analytics
    image: supabase/logflare:1.14.2
    deploy:
      restart_policy:
        condition: on-failure
    networks:
      - supabase-net
    ports:
      - 4000:4000
    healthcheck:
      test:
        - CMD
        - curl
        - http://localhost:4000/health
      timeout: 5s
      interval: 5s
      retries: 10
    depends_on:
      - db
    environment:
      LOGFLARE_NODE_HOST: 127.0.0.1
      DB_USERNAME: supabase_admin
      DB_DATABASE: _supabase
      DB_HOSTNAME: {{ POSTGRES_HOST }}
      DB_PORT: {{ POSTGRES_PORT }}
      DB_PASSWORD: {{ POSTGRES_PASSWORD }}
      DB_SCHEMA: _analytics
      LOGFLARE_PUBLIC_ACCESS_TOKEN: {{ LOGFLARE_PUBLIC_ACCESS_TOKEN }}
      LOGFLARE_PRIVATE_ACCESS_TOKEN: {{ LOGFLARE_PRIVATE_ACCESS_TOKEN }}
      LOGFLARE_SINGLE_TENANT: "true"
      LOGFLARE_SUPABASE_MODE: "true"
      LOGFLARE_MIN_CLUSTER_SIZE: 1
      POSTGRES_BACKEND_URL: "postgresql://supabase_admin:{{ POSTGRES_PASSWORD }}@{{ POSTGRES_HOST }}:{{ POSTGRES_PORT }}/_supabase"
      POSTGRES_BACKEND_SCHEMA: _analytics
      LOGFLARE_FEATURE_FLAG_OVERRIDE: multibackend=true

  db:
    hostname: db
    image: supabase/postgres:17.4.1.043
    networks:
      - supabase-net
    volumes:
      - /mnt/nfs/shared/supabase/db/realtime.sql:/docker-entrypoint-initdb.d/migrations/99-realtime.sql:Z
      - /mnt/nfs/shared/supabase/db/webhooks.sql:/docker-entrypoint-initdb.d/init-scripts/98-webhooks.sql:Z
      - /mnt/nfs/shared/supabase/db/roles.sql:/docker-entrypoint-initdb.d/init-scripts/99-roles.sql:Z
      - /mnt/nfs/shared/supabase/db/jwt.sql:/docker-entrypoint-initdb.d/init-scripts/99-jwt.sql:Z
      - /mnt/nfs/shared/supabase/db/data:/var/lib/postgresql/data:Z
      - /mnt/nfs/shared/supabase/db/_supabase.sql:/docker-entrypoint-initdb.d/migrations/97-_supabase.sql:Z
      - /mnt/nfs/shared/supabase/db/logs.sql:/docker-entrypoint-initdb.d/migrations/99-logs.sql:Z
      - /mnt/nfs/shared/supabase/db/pooler.sql:/docker-entrypoint-initdb.d/migrations/99-pooler.sql:Z
      - db-config:/etc/postgresql-custom
    healthcheck:
      test:
        - CMD
        - pg_isready
        - -U
        - postgres
        - -h
        - localhost
      interval: 5s
      timeout: 5s
      retries: 10
    depends_on:
      - vector
    deploy:
      replicas: 1
      placement:
        constraints: [node.platform.arch == x86_64]
      restart_policy:
        condition: on-failure
      endpoint_mode: dnsrr
    environment:
      POSTGRES_HOST: /var/run/postgresql
      PGPORT: {{ POSTGRES_PORT }}
      POSTGRES_PORT: {{ POSTGRES_PORT }}
      PGPASSWORD: {{ POSTGRES_PASSWORD }}
      POSTGRES_PASSWORD: {{ POSTGRES_PASSWORD }}
      PGDATABASE: {{ POSTGRES_DB }}
      POSTGRES_DB: {{ POSTGRES_DB }}
      JWT_SECRET: {{ JWT_SECRET }}
      JWT_EXP: {{ JWT_EXPIRY }}
    command:
      - postgres
      - -c
      - config_file=/etc/postgresql/postgresql.conf
      - -c
      - log_min_messages=fatal

  vector:
    hostname: vector
    image: timberio/vector:0.28.1-alpine
    networks:
      - supabase-net
    volumes:
      - /mnt/nfs/shared/supabase/logs/vector.yml:/etc/vector/vector.yml:ro,z
      - {{ DOCKER_SOCKET_LOCATION }}:/var/run/docker.sock:ro,z
    healthcheck:
      test:
        - CMD
        - wget
        - --no-verbose
        - --tries=1
        - --spider
        - "http://vector:9001/health"
      timeout: 5s
      interval: 5s
      retries: 3
    deploy:
      replicas: 1
      placement:
        constraints: [node.platform.arch == x86_64]
      restart_policy:
        condition: on-failure
    environment:
      LOGFLARE_PUBLIC_ACCESS_TOKEN: {{ LOGFLARE_PUBLIC_ACCESS_TOKEN }}
    command:
      - --config
      - /etc/vector/vector.yml
    security_opt:
      - label=disable

  supavisor:
    hostname: supavisor
    image: supabase/supavisor:2.5.1
    networks:
      - supabase-net
    healthcheck:
      test: ["CMD", "curl", "-sSfL", "--head", "-o", "/dev/null", "http://127.0.0.1:4000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - target: 5432
        published: {{ POSTGRES_PORT }}
        protocol: tcp
        mode: host
      - target: 6543
        published: {{ POOLER_PROXY_PORT_TRANSACTION }}
        protocol: tcp
        mode: host
    volumes:
      - /mnt/nfs/shared/supabase/pooler/pooler.exs:/etc/pooler/pooler.exs:ro,z
    depends_on:
      - db
      - analytics
    deploy:
      replicas: 1
      placement:
        constraints: [node.platform.arch == x86_64]
      restart_policy:
        condition: on-failure
    environment:
      PORT: 4000
      POSTGRES_PORT: {{ POSTGRES_PORT }}
      POSTGRES_DB: {{ POSTGRES_DB }}
      POSTGRES_PASSWORD: {{ POSTGRES_PASSWORD }}
      DATABASE_URL: "ecto://supabase_admin:{{ POSTGRES_PASSWORD }}@db:{{ POSTGRES_PORT }}/_supabase"
      CLUSTER_POSTGRES: 1
      SECRET_KEY_BASE: {{ SECRET_KEY_BASE }}
      VAULT_ENC_KEY: {{ VAULT_ENC_KEY }}
      API_JWT_SECRET: {{ JWT_SECRET }}
      METRICS_JWT_SECRET: {{ JWT_SECRET }}
      REGION: "local"
      ERL_AFLAGS: "-proto_dist inet_tcp"
      POOLER_TENANT_ID: {{ POOLER_TENANT_ID }}
      POOLER_DEFAULT_POOL_SIZE: {{ POOLER_DEFAULT_POOL_SIZE }}
      POOLER_MAX_CLIENT_CONN: {{ POOLER_MAX_CLIENT_CONN }}
      POOLER_POOL_MODE: "transaction"
    command: >
      /bin/sh -c "/app/bin/migrate && /app/bin/supavisor eval \"$$(cat /etc/pooler/pooler.exs)\" && /app/bin/server"
